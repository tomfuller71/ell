{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import ell\n",
    "from pydantic import BaseModel, Field\n",
    "import random\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "ell.init(store=\"./ell-store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foundational Guidance from ChatGPT on best practises\n",
    "\n",
    "Here are some best practices for creating multiple-choice questions and options:\n",
    "\n",
    "**Question Writing:**\n",
    "\n",
    "- Clarity: Ensure the question is clear and unambiguous.\n",
    "- Focus: Test a single, specific concept or skill.\n",
    "- Relevance: Relate the question directly to the key learning objectives.\n",
    "- Avoid Trick Questions: Ensure the question doesn't rely on confusing wording or unnecessary complexity.\n",
    "- Balance Complexity: Aim for moderate difficulty, avoiding overly simple or overly complex questions.\n",
    "\n",
    "\n",
    "**Option Writing:**\n",
    "\n",
    "- Plausible Distractors: All options (distractors) should seem plausible to less knowledgeable students.\n",
    "- Single Correct Answer: Only one option should be clearly correct.\n",
    "- Consistent Length: Avoid making the correct answer noticeably longer or shorter than the distractors.\n",
    "- Avoid Negative Wording: If unavoidable, highlight the negative (e.g., not).\n",
    "- Mutually Exclusive: Options should not overlap in meaning.\n",
    "- Avoid \"All of the Above\"/\"None of the Above\": These can confuse or test for test-taking strategies rather than knowledge.\n",
    "\n",
    "**Difficulty Rating (1 to 5 Scale):**\n",
    "\n",
    "- \"1\" Easy:\n",
    "    - Tests basic recall of facts or definitions.\n",
    "    - Requires minimal cognitive effort.\n",
    "    - Candidates can answer quickly without much analysis.\n",
    "- \"2\" Below Moderate:\n",
    "    - Involves basic understanding or straightforward application of concepts.\n",
    "    - May require recognition of patterns or simple reasoning.\n",
    "- \"3\" Moderate:\n",
    "    - Requires applying concepts in new or slightly varied contexts.\n",
    "    - Involves some critical thinking and deeper understanding.\n",
    "    - Slightly more complex than a simple recall.\n",
    "- \"4\" Hard:\n",
    "    - Requires significant analysis, problem-solving, or synthesis.\n",
    "    - May involve multiple concepts or require candidates to infer information.\n",
    "    - Challenging for most candidates, requiring both time and thought.\n",
    "- \"5\" Very Hard:\n",
    "    - Requires advanced critical thinking, evaluation, or comprehensive understanding.\n",
    "    - May involve abstract concepts or complex scenarios.\n",
    "    - Likely to challenge even the top-performing candidates\n",
    "\n",
    "**Question Rating(1-5 scale):**\n",
    "\n",
    "Here’s a scale for how well a multiple-choice question fits the evaluation criteria:\n",
    "\n",
    "- \"1\" Poor:\n",
    "    - The question is unclear or ambiguous, making it difficult for students to understand.\n",
    "    - The question is irrelevant or does not assess an important learning objective.\n",
    "    - Distractors are implausible or obviously incorrect.\n",
    "    - The options are unbalanced (e.g., the correct answer stands out due to length or wording).\n",
    "    - The question may have more than one plausible answer or is biased.\n",
    "- \"2\" Below Average:\n",
    "    - The question is somewhat clear but may contain minor ambiguities.\n",
    "    - The question relates to the content but does not target key concepts or skills.\n",
    "    - Distractors are weak but somewhat plausible.\n",
    "    - Some imbalance in options (e.g., the correct answer is slightly longer or more detailed).\n",
    "    - The question is somewhat fair but might confuse less knowledgeable students.\n",
    "- \"3\" Average:\n",
    "    - The question is generally clear but could be improved for better understanding.\n",
    "    - The question is relevant to learning objectives but might be too broad or narrow.\n",
    "    - Distractors are reasonably plausible but not challenging enough.\n",
    "    - The options are mostly balanced, with minor improvements needed.\n",
    "    - The question is fair, with a clear correct answer and minimal bias.\n",
    "- \"4\" Good:\n",
    "    - The question is clear and concise with no ambiguities.\n",
    "    - The question effectively targets key learning objectives or skills.\n",
    "    - Distractors are plausible and make the question moderately challenging.\n",
    "    - The options are well-balanced, with no standout option based on length or structure.\n",
    "    - The question is fair and unbiased, with a well-defined correct answer.\n",
    "- \"5\" Excellent:\n",
    "    - The question is exceptionally clear and concise, easy to understand with no ambiguities.\n",
    "    - The question is highly relevant, focusing directly on key learning objectives.\n",
    "    - Distractors are carefully crafted, highly plausible, and challenging for all students.\n",
    "    - The options are perfectly balanced in length, structure, and content.\n",
    "    - The question is completely fair, with no bias or confusion, and has a single, well-defined correct answer.\n",
    "    \n",
    "This scale allows you to assess and refine questions based on how well they align with the evaluation criteria for clarity, relevance, plausibility, balance, and fairness.\n",
    "\n",
    "**Mix of questions**\n",
    "\n",
    "For setting 10 multiple-choice questions with difficulty levels.\n",
    "\n",
    " - Balanced Distribution: Aim for a mixture of difficulties that covers a wide range of skills and understanding levels.\n",
    "\n",
    "    - 2 easy (1): Questions that test basic recall or fundamental concepts.\n",
    "    - 3 below-moderate / moderate (2-3): Questions that require some application of knowledge or understanding of concepts.\n",
    "    - 3 difficult (4): Questions that challenge critical thinking or deeper understanding.\n",
    "    - 2 very difficult (5): Questions that test advanced knowledge or complex problem-solving.\n",
    "- Progressive Difficulty: Arrange the questions so they gradually increase in difficulty to help build student confidence early on. For example:\n",
    "    - Questions 1-2: Difficulty 1 (easy)\n",
    "    - Questions 3-5: Difficulty 2-3 (moderate)\n",
    "    - Questions 6-8: Difficulty 4 (hard)\n",
    "    - Questions 9-10: Difficulty 5 (very hard)\n",
    "- Cover All Key Topics: Ensure questions cover a range of topics or learning objectives, not just focusing on the hardest or easiest parts of the content.\n",
    "- Testing Different Cognitive Skills: Use easy questions for simple recall, moderate ones for application, and hard ones for analysis, synthesis, or evaluation.\n",
    "\n",
    "This way, the exam fairly assesses both foundational knowledge and higher-order thinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFFICULTY_RATINGS = {\n",
    "    \"1\": \"The question should be easy and should be answered correctly by most students. It should test basic recall of facts or definitions, requires minimal cognitive effort and can be answered quickly without much analysis.\",\n",
    "    \"2\": \"The question shopuld be of below moderate difficulty and should be answered correctly by most students. It should involve basic understanding or straightforward application of concepts. It may require recognition of patterns or simple reasoning.\",\n",
    "    \"3\": \"The question should be of moderate difficulty. It may require applying concepts in new or slightly varied contexts,  involving some critical thinking and deeper understanding.  It shoudl be more complex than a simple recall.\",\n",
    "    \"4\": \"The question should be of hard difficulty and should be challenging for most candidates, requiring both time and thought. It should require significant analysis, problem-solving, or synthesis. It may involve multiple concepts or require candidates to infer information.\",\n",
    "    \"5\": \"The question should be of very hard difficulty and ikely to challenge even the top-performing students. It should require advanced critical thinking, evaluation, or comprehensive understanding. It may involve abstract concepts or complex scenarios.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Option(BaseModel):\n",
    "    text: str = Field(description=\"The option to add as a distractor.\")\n",
    "    correct: bool = Field(\n",
    "        description=\"Whether or not this option is the correct answer.\"\n",
    "    )\n",
    "    explanation: str = Field(\n",
    "        description=\"An explanation for the option - either why it is incorrect or why it is correct.\"\n",
    "    )\n",
    "\n",
    "class Question(BaseModel):\n",
    "    conceptsTested: list[str] = Field(\n",
    "        description=\"The key concept or concepts for the tutoring subject that the question is testing.\"\n",
    "    )\n",
    "    question: str = Field(description=\"The question to ask.\")\n",
    "    answer: Option = Field(description=\"The correct answer to the question.\")\n",
    "    distractors: list[Option] = Field(description=\"The distractors for the question.\")\n",
    "\n",
    "\n",
    "def shuffledQuestion(question) -> list[Option]:\n",
    "    \"\"\"Combines the correct answer with the distractors and returns a shuffled list of options.\"\"\"\n",
    "    options = [question.answer, *question.distractors]\n",
    "    random.shuffle(options)\n",
    "    return options\n",
    "\n",
    "\n",
    "def question_to_string(question, show_correct_option=True, show_explanations=True) -> str:\n",
    "    \"\"\"\n",
    "    Converts the question and its options with explanations into a string representation.\n",
    "    :param question: Question, the question object containing the question and options\n",
    "    \"\"\"\n",
    "\n",
    "    str_rep = question.question + \"\\n\"\n",
    "    for letter, option in zip([\"A\", \"B\", \"C\", \"D\"], shuffledQuestion(question)):\n",
    "        tick_or_cross = \"\\u2705\" if option.correct else \"\\u274C\"\n",
    "        str_rep += f\"\\n{letter}. {option.text} {tick_or_cross if show_correct_option else ''}\"\n",
    "        if show_explanations:\n",
    "            str_rep += f\"\\n{option.explanation}\\n\"\n",
    "    str_rep += \"\\n\"\n",
    "    return str_rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate question prompt function\n",
    "@ell.complex(model=\"gpt-4o-2024-08-06\", response_format=Question)\n",
    "def generate_mc_question(target_difficulty: int = 3, concepts: list[str] | None = None):\n",
    "    \"\"\"You are a dedicated Chemistry Tutor specializing in Advanced General Chemistry, using \"Principles of Modern Chemistry\" by Oxtoby, Gillis and Butler.\n",
    "    \"\"\"\n",
    "    concepts_str = f\"of {' ,'.join(concepts)}\" if concepts else \"in the chapters\"\n",
    "    return f\"Generate a multiple choice question suitable for an undergraduate mid-term exam based on chapters 1-11 from the textbook. The question should test the key concepts {concepts_str} and follow best practices for question and option writing. {DIFFICULTY_RATINGS[str(target_difficulty)]}.\"\n",
    "\n",
    "def create_new_question(target_difficulty: int = 3, concepts: list[str] | None = None):\n",
    "    \"\"\"\n",
    "    Creates a new question with the given target difficulty and concepts.\n",
    "    :param target_difficulty: int, the target difficulty of the question\n",
    "    :param concepts: list[str], the concepts that the question should test\n",
    "    \"\"\"\n",
    "    response = generate_mc_question(target_difficulty=target_difficulty, concepts=concepts)\n",
    "    question =  response.parsed # type: ignore\n",
    "    return question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multiple Choice  question\n",
    "question = create_new_question(target_difficulty=4, concepts=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider a reversible reaction with the following equilibrium constant expression at a given temperature: K_eq = \\frac{[C]^c[D]^d}{[A]^a[B]^b}. Which of the following statements is true regarding the effect of temperature on the equilibrium position if the reaction is exothermic?\n",
      "\n",
      "A. The equilibrium position will shift towards the reactants as temperature increases. ✅\n",
      "For an exothermic reaction, increasing the temperature shifts the equilibrium position towards the reactants according to Le Chatelier's principle, since the system compensates for the added heat by favoring the endothermic reverse reaction.\n",
      "\n",
      "B. The equilibrium constant K_eq remains unchanged with temperature changes. ❌\n",
      "The equilibrium constant depends on temperature. For an exothermic reaction, K_eq decreases with increasing temperature.\n",
      "\n",
      "C. The equilibrium constant K_eq will increase as temperature increases. ❌\n",
      "For an exothermic reaction, the equilibrium constant K_eq actually decreases with an increase in temperature because the equilibrium favors the reactants.\n",
      "\n",
      "D. The equilibrium position will shift towards the products as temperature increases. ❌\n",
      "This statement is true for endothermic reactions, but for exothermic reactions like the one in the question, increasing temperature shifts the equilibrium towards the reactants.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(question_to_string(question, show_correct_option=True, show_explanations=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to review correctness of a question and evaluate whether it is a good question\n",
    "\n",
    "class QuestionReview(BaseModel):\n",
    "    correct: bool = Field(description=\"Whether the question is correct.\")\n",
    "    difficulty: int = Field(description=\"The difficulty of the question where 1 is easy, 2-3 is moderate, 4 is difficult and 5 is very difficult.\")\n",
    "    feedback: str = Field(description=\"Feedback on the question.\")\n",
    "    rating: int = Field(description=\"The rating of the question, from 1 to 5 where 1 is poor and 5 is excellent.\")\n",
    "\n",
    "@ell.complex(model=\"gpt-4o-2024-08-06\", response_format=QuestionReview)\n",
    "def generate_review_mc_question(question: Question):\n",
    "    \"\"\"You are a dedicated Chemistry Tutor specializing in Advanced General Chemistry, using \"Principles of Modern Chemistry\" by Oxtoby, Gillis and Butler.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    The following multiple choice question is based on the key concepts in chapters 1-11 of the textbook \"Principles of Modern Chemistry\" by Oxtoby, Gillis and Butler.\n",
    "\n",
    "    {question_to_string(question, show_correct_option=True, show_explanations=True)}\n",
    "\n",
    "    Review this multiple choice question and provide feedback.  In your review the following:\n",
    "    - Indicate whether the answer provided for question is in fact correct.\n",
    "    - Rate the difficulty of the question on a scale of 1 to 5, where 1 is easy and 5 is very difficult using the following guidelines:\n",
    "        - \"1\" Easy:\n",
    "            - Tests basic recall of facts or definitions.\n",
    "            - Requires minimal cognitive effort.\n",
    "            - Candidates can answer quickly without much analysis.\n",
    "        - \"2\" Below Moderate:\n",
    "            - Involves basic understanding or straightforward application of concepts.\n",
    "            - May require recognition of patterns or simple reasoning.\n",
    "        - \"3\" Moderate:\n",
    "            - Requires applying concepts in new or slightly varied contexts.\n",
    "            - Involves some critical thinking and deeper understanding.\n",
    "            - Slightly more complex than a simple recall.\n",
    "        - \"4\" Hard:\n",
    "            - Requires significant analysis, problem-solving, or synthesis.\n",
    "            - May involve multiple concepts or require candidates to infer information.\n",
    "            - Challenging for most candidates, requiring both time and thought.\n",
    "        - \"5\" Very Hard:\n",
    "            - Requires advanced critical thinking, evaluation, or comprehensive understanding.\n",
    "            - May involve abstract concepts or complex scenarios.\n",
    "            - Likely to challenge even the top-performing candidates\n",
    "    - Provide feedback on the clarity, focus, relevance, complexity, and balance of the question and options using the following guidelines:\n",
    "        - \"1\" Poor:\n",
    "            - The question is unclear or ambiguous, making it difficult for students to understand.\n",
    "            - The question is irrelevant or does not assess an important learning objective.\n",
    "            - Distractors are implausible or obviously incorrect.\n",
    "            - The options are unbalanced (e.g., the correct answer stands out due to length or wording).\n",
    "            - The question may have more than one plausible answer or is biased.\n",
    "        - \"2\" Below Average:\n",
    "            - The question is somewhat clear but may contain minor ambiguities.\n",
    "            - The question relates to the content but does not target key concepts or skills.\n",
    "            - Distractors are weak but somewhat plausible.\n",
    "            - Some imbalance in options (e.g., the correct answer is slightly longer or more detailed).\n",
    "            - The question is somewhat fair but might confuse less knowledgeable students.\n",
    "        - \"3\" Average:\n",
    "            - The question is generally clear but could be improved for better understanding.\n",
    "            - The question is relevant to learning objectives but might be too broad or narrow.\n",
    "            - Distractors are reasonably plausible but not challenging enough.\n",
    "            - The options are mostly balanced, with minor improvements needed.\n",
    "            - The question is fair, with a clear correct answer and minimal bias.\n",
    "        - \"4\" Good:\n",
    "            - The question is clear and concise with no ambiguities.\n",
    "            - The question effectively targets key learning objectives or skills.\n",
    "            - Distractors are plausible and make the question moderately challenging.\n",
    "            - The options are well-balanced, with no standout option based on length or structure.\n",
    "            - The question is fair and unbiased, with a well-defined correct answer.\n",
    "        - \"5\" Excellent:\n",
    "            - The question is exceptionally clear and concise, easy to understand with no ambiguities.\n",
    "            - The question is highly relevant, focusing directly on key learning objectives.\n",
    "            - Distractors are carefully crafted, highly plausible, and challenging for all students.\n",
    "            - The options are perfectly balanced in length, structure, and content.\n",
    "            - The question is completely fair, with no bias or confusion, and has a single, well-defined correct answer.\n",
    "    \"\"\"\n",
    "\n",
    "def review_question(question):\n",
    "    response = generate_review_mc_question(question)\n",
    "    return response.parsed # type: ignore\n",
    "\n",
    "def review_to_string(review):\n",
    "    return f\"Correct: {review.correct}\\nDifficulty: {review.difficulty}\\nRating: {review.rating}\\nFeedback:\\n{review.feedback}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = review_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: True\n",
      "Difficulty: 2\n",
      "Rating: 4\n",
      "Feedback:\n",
      "The question is clear and tests the basic understanding of the effect of temperature on an equilibrium involving an exothermic reaction, which is an important concept in chemistry. The distractors are plausible and require the students to apply their knowledge of Le Chatelier's principle correctly, making the task more than simple recall. However, it primarily relies on basic understanding rather than deeper analysis or multi-step reasoning. The question is relevant, the options are well-balanced without any obvious gives, and it aligns well with key learning objectives regarding chemical equilibria and thermodynamics.\n"
     ]
    }
   ],
   "source": [
    "print(review_to_string(review))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
